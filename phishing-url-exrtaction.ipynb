{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\n!pip3 install bs4\n!pip install python-whois","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom urllib.parse import urlparse,urlencode\nimport re\nfrom bs4 import BeautifulSoup\nimport requests\nimport whois\nimport urllib.request\nfrom datetime import datetime\nimport time\nimport socket\nfrom urllib.error import HTTPError\nfrom cython.parallel import prange\nfrom dateutil.parser import parse as date_parse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url='https://raw.githubusercontent.com/vaish0705/phishweb/main/phishingurl%20-%20Sheet1.csv'\ndf=pd.read_csv(url)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.iloc[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"computer_raw_data=df\ncomputer_raw_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd = None\nclass FeatureExtraction:\n    def __init__(self):\n        pass\n    \n    def getProtocol(self,url):\n        return urlparse(url).scheme\n\n    def getDomain(self,url):\n        return urlparse(url).netloc\n    \n    def getPath(self,url):\n        return urlparse(url).path\n    \n    def havingIP(self,url):\n        \"\"\"If the domain part has IP then it is phishing otherwise legitimate\"\"\"\n        match=re.search('(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  #IPv4\n                    '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)'  #IPv4 in hexadecimal\n                    '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}',url)     #Ipv6\n        if match:\n            #print match.group()\n            return 1            # phishing\n        else:\n            #print 'No matching pattern found'\n            return 0            # legitimate\n        \n    def getDepth(self,url):\n        s = urlparse(url).path.split('/')\n        depth = 0\n        for j in range(len(s)):\n            if len(s[j]) != 0:\n                depth = depth+1\n        return depth\n    \n    def long_url(self,url):\n        \"\"\"This function is defined in order to differntiate website based on the length of the URL\"\"\"\n        if len(url) < 54:\n            return 0            # legitimate\n        elif len(url) >= 54 and len(url) <= 75:\n            return 2            # suspicious\n        else:\n            return 1            # phishing\n    \n    def have_at_symbol(self,url):\n        \"\"\"This function is used to check whether the URL contains @ symbol or not\"\"\"\n        if \"@\" in url:\n            return 1            # phishing\n        else:\n            return 0            # legitimate\n    \n    def redirection(self,url):\n        \"\"\"If the url has symbol(//) after protocol then such URL is to be classified as phishing \"\"\"\n        if \"//\" in urlparse(url).path:\n            return 1            # phishing\n        else:\n            return 0            # legitimate\n        \n    def prefix_suffix_separation(self,url):\n        \"\"\"If the domain has '-' symbol then it is considered as phishing site\"\"\"\n        if \"-\" in urlparse(url).netloc:\n            return 1            # phishing\n        else:\n            return 0            # legitimate\n        \n    def sub_domains(self,url):\n        \"\"\"If the url has more than 3 dots then it is a phishing\"\"\"\n        if url.count(\".\") < 3:\n            return 0            # legitimate\n        elif url.count(\".\") == 3:\n            return 2            # suspicious\n        else:\n            return 1            # phishing\n        \n    def shortening_service(self,url):\n        \"\"\"Tiny URL -> phishing otherwise legitimate\"\"\"\n        match=re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n                    'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n                    'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n                    'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n                    'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n                    'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n                    'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|tr\\.im|link\\.zip\\.net',url)\n        if match:\n            return 1               # phishing\n        else:\n            return 0               # legitimate\n        \n    \"\"\"\n    def google_index(self,url):\n        user_agent = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36'\n        headers = { 'User-Agent' : user_agent}\n        query = {'q': 'info:' + url}\n        google = \"https://www.google.com/search?\" + urlencode(query)\n        #data = requests.get(google, headers=headers,proxies=proxies)\n        data = requests.get(google,headers=headers)\n        data.encoding = 'ISO-8859-1'\n        soup = BeautifulSoup(str(data.content), \"html.parser\")\n        try:\n            check = soup.find(id=\"rso\").find(\"div\").find(\"div\").find(\"h3\").find(\"a\")\n            if soup.find(id=\"rso\").find(\"div\").find(\"div\").find(\"h3\").find(\"a\").find(\"href\" != None):\n                href = check['href']\n                return 0 # indexed\n            else:\n                return 1\n        except AttributeError:\n            return 1 # indexed\n        #print(\"Waiting \" + str(seconds) + \" seconds until checking next URL.\\n\")\n        #time.sleep(float(seconds))\n    \"\"\"\n    \"\"\"\n    def abnormal_url(self,url):\n        dns = 0\n        #domain_name = \"\"\n        try:\n            #domain = urlparse(url).netloc\n            #print(domain)\n            domain_name = whois.whois(urlparse(url).netloc)\n            #print(domain_name)\n        except:\n            dns = 1\n        \n        if dns == 1:\n            return 1 # phishing\n        else:\n            hostname=domain_name.domain_name\n            #match=re.search(hostname,url)\n            if hostname in url:\n                return 0 # legitimate\n            else:\n                return 1 # phishing\n    \"\"\"\n    \n    #def web_traffic(self,url):\n       # try:\n        #    rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\"REACH\")['RANK']\n        #except TypeError:\n         #   return 1\n        #except HTTPError:\n         #   return 2\n        #rank= int(rank)\n        #if (rank<100000):\n         #   return 0\n        #else:\n          #  return 2\n        \n   \n        \n    def domain_registration_length(self,url):\n        dns = 0\n        try:\n            domain_name = whois.whois(urlparse(url).netloc)\n        except:\n            dns = 1\n        \n        if dns == 1:\n            return 1      #phishing\n        else:\n            expiration_date = domain_name.expiration_date\n            today = time.strftime('%Y-%m-%d')\n            today = datetime.strptime(today, '%Y-%m-%d')\n            if expiration_date is None:\n                return 1\n            elif type(expiration_date) is list or type(today) is list :\n                return 2     #If it is a type of list then we can't select a single value from list. So,it is regarded as suspected website  \n            else:\n                creation_date = domain_name.creation_date\n                expiration_date = domain_name.expiration_date\n                if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n                    try:\n                        creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n                        expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n                    except:\n                        return 2\n                registration_length = abs((expiration_date - today).days)\n                if registration_length / 365 <= 1:\n                    return 1 #phishing\n                else:\n                    return 0 # legitimate\n            \n    def age_domain(self,url):\n        dns = 0\n        try:\n            domain_name = whois.whois(urlparse(url).netloc)\n        except:\n            dns = 1\n        \n        if dns == 1:\n            return 1\n        else:\n            creation_date = domain_name.creation_date\n            expiration_date = domain_name.expiration_date\n            if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n                try:\n                    creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n                    expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n                except:\n                    return 2\n            if ((expiration_date is None) or (creation_date is None)):\n                return 1\n            elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n                return 2\n            else:\n                ageofdomain = abs((expiration_date - creation_date).days)\n                if ((ageofdomain/30) < 6):\n                    return 1\n                else:\n                    return 0\n     \n    \n    def dns_record(self,url):\n        dns = 0\n        try:\n            domain_name = whois.whois(urlparse(url).netloc)\n            #rint(domain_name)\n        except:\n            dns = 1\n        \n        if dns == 1:\n            return 1\n        else:\n            return 0\n        \n   \n    def statistical_report(self,url):\n        hostname = url\n        h = [(x.start(0), x.end(0)) for x in re.finditer('https://|http://|www.|https://www.|http://www.', hostname)]\n        z = int(len(h))\n        if z != 0:\n            y = h[0][1]\n            hostname = hostname[y:]\n            h = [(x.start(0), x.end(0)) for x in re.finditer('/', hostname)]\n            z = int(len(h))\n            if z != 0:\n                hostname = hostname[:h[0][0]]\n        url_match=re.search('at\\.ua|usa\\.cc|baltazarpresentes\\.com\\.br|pe\\.hu|esy\\.es|hol\\.es|sweddy\\.com|myjino\\.ru|96\\.lt|ow\\.ly',url)\n        try:\n            ip_address = socket.gethostbyname(hostname)\n            ip_match=re.search('146\\.112\\.61\\.108|213\\.174\\.157\\.151|121\\.50\\.168\\.88|192\\.185\\.217\\.116|78\\.46\\.211\\.158|181\\.174\\.165\\.13|46\\.242\\.145\\.103|121\\.50\\.168\\.40|83\\.125\\.22\\.219|46\\.242\\.145\\.98|107\\.151\\.148\\.44|107\\.151\\.148\\.107|64\\.70\\.19\\.203|199\\.184\\.144\\.27|107\\.151\\.148\\.108|107\\.151\\.148\\.109|119\\.28\\.52\\.61|54\\.83\\.43\\.69|52\\.69\\.166\\.231|216\\.58\\.192\\.225|118\\.184\\.25\\.86|67\\.208\\.74\\.71|23\\.253\\.126\\.58|104\\.239\\.157\\.210|175\\.126\\.123\\.219|141\\.8\\.224\\.221|10\\.10\\.10\\.10|43\\.229\\.108\\.32|103\\.232\\.215\\.140|69\\.172\\.201\\.153|216\\.218\\.185\\.162|54\\.225\\.104\\.146|103\\.243\\.24\\.98|199\\.59\\.243\\.120|31\\.170\\.160\\.61|213\\.19\\.128\\.77|62\\.113\\.226\\.131|208\\.100\\.26\\.234|195\\.16\\.127\\.102|195\\.16\\.127\\.157|34\\.196\\.13\\.28|103\\.224\\.212\\.222|172\\.217\\.4\\.225|54\\.72\\.9\\.51|192\\.64\\.147\\.141|198\\.200\\.56\\.183|23\\.253\\.164\\.103|52\\.48\\.191\\.26|52\\.214\\.197\\.72|87\\.98\\.255\\.18|209\\.99\\.17\\.27|216\\.38\\.62\\.18|104\\.130\\.124\\.96|47\\.89\\.58\\.141|78\\.46\\.211\\.158|54\\.86\\.225\\.156|54\\.82\\.156\\.19|37\\.157\\.192\\.102|204\\.11\\.56\\.48|110\\.34\\.231\\.42',ip_address)  \n        except:\n            return 1\n\n        if url_match:\n            return 1\n        else:\n            return 0\n        \n    def https_token(self,url):\n        match=re.search('https://|http://',url)\n        try:\n            if match.start(0)==0 and match.start(0) is not None:\n                url=url[match.end(0):]\n                match=re.search('http|https',url)\n                if match:\n                    return 1\n                else:\n                    return 0\n        except:\n            return 1\n    \n    def httpDomain(self,url):\n#         print(url)\n        protocol = urlparse(url).netloc\n#         print(protocol)\n#         return check(url,substr)\n        if 'https' in url:\n            return 0\n        else:\n            return 1\n    \n    def port(self,url):\n        port=urlparse(url).port\n        if port:\n            return 1\n        else:\n            return 0\n    \n    def favicon(self,url):\n        try:\n            response = requests.get(url)\n            soup = BeautifulSoup(response.text, 'html.parser')\n        except:\n            response = \"\"\n            soup = -999\n        if soup == -999:\n            return 1\n        else:\n            try:\n                for head in soup.find_all('head'):\n                    for head.link in soup.find_all('link', href=True):\n                        dots = [x.start(0)\n                                for x in re.finditer('\\.', head.link['href'])]\n                        if url in head.link['href'] or len(dots) == 1 or domain in head.link['href']:\n                            return 0\n                            raise StopIteration\n                        else:\n                            return 1\n                            raise StopIteration\n            except StopIteration:\n                pass\n    def iframe(self,url):\n        try:\n            response = requests.get(url)\n        except:\n            response = \"\"\n        if response == \"\":\n            return 1\n        else:\n            if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n                return 0\n            else:\n                return 1\n            \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features\nprotocol = []\ndomain = []\npath = []\ngetDepth = []\nhaving_ip = []\nlen_url = []\nhaving_at_symbol = []\nredirection_symbol = []\nprefix_suffix_separation = []\nsub_domains = []\ntiny_url = []\n#abnormal_url = []\n#web_traffic = []\n#domain_registration_length = []\n#dns_record = []\nstatistical_report = []\nage_domain = []\nhttp_tokens = []\nhttpDomain = []\niframe = []\nport = []\nfavicon = []\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fe = FeatureExtraction()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp='http://https-www-paypal-it-webapps-mpp-home.soft-hair.com/'\nprint(computer_raw_data[0])\nfe.iframe(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrows = len(computer_raw_data)\nprint(rows)\nfor i in range(0,rows):\n    url=computer_raw_data[i]\n#     print(url)\n    protocol.append(fe.getProtocol(url))\n    path.append(fe.getPath(url))\n    getDepth.append(fe.getDepth(url))\n    domain.append(fe.getDomain(url))\n    having_ip.append(fe.havingIP(url))\n    len_url.append(fe.long_url(url))\n    having_at_symbol.append(fe.have_at_symbol(url))\n    redirection_symbol.append(fe.redirection(url))\n    prefix_suffix_separation.append(fe.prefix_suffix_separation(url))\n    sub_domains.append(fe.sub_domains(url))\n    tiny_url.append(fe.shortening_service(url))\n#    web_traffic.append(fe.web_traffic(url))\n#     domain_registration_length.append(fe.domain_registration_length(url))\n#    dns_record.append(fe.dns_record(url))\n#     statistical_report.append(fe.statistical_report(url))\n#    age_domain.append(fe.age_domain(url))\n    http_tokens.append(fe.https_token(url))\n    httpDomain.append(fe.httpDomain(url))\n#    try:\n#        response = requests.get(url)\n#    except:\n#        response = \"\"\n#     iframe.append(fe.iframe(url))\n    port.append(fe.port(url))\n#     try:\n#         response = requests.get(url)\n#         soup = BeautifulSoup(response.text, 'html.parser')\n#     except:\n#         response = \"\"\n#         soup = -999\n#     favicon.append(fe.favicon(url))\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = []\nfor i in range(0,rows):\n    label.append(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d={'Protocol':pd.Series(protocol),'Domain':pd.Series(domain),'Path':pd.Series(path),'Depth_url':pd.Series(getDepth),'Having_IP':pd.Series(having_ip),\n   'URL_Length':pd.Series(len_url),'Having_@_symbol':pd.Series(having_at_symbol),\n   'Redirection_//_symbol':pd.Series(redirection_symbol),'Prefix_suffix_separation':pd.Series(prefix_suffix_separation),\n   'Sub_domains':pd.Series(sub_domains),'tiny_url':pd.Series(tiny_url),\n   'http_tokens':pd.Series(http_tokens),'httpDomain':pd.Series(httpDomain),'Port':pd.Series(port),\n   'label':pd.Series(label)}\ndata=pd.DataFrame(d)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv(\"phishing-urls.csv\",index=False,encoding='UTF-8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(data)):\n    for j in range(3,15):\n        if(math.isnan(data.iloc[i,j])):\n            temp.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(data)):\n    for j in range(3,15):\n        if(math.isnan(data.iloc[i,j])):\n            temp.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv(\"phishing-urls.csv\",index=False,encoding='UTF-8')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}